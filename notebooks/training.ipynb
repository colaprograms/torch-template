{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ctc-test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colaprograms/2019-hackathon-ocr-wymbah/blob/master/notebooks/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6yXMI_CfA3s",
        "colab_type": "text"
      },
      "source": [
        "This notebook trains a model!\n",
        "\n",
        "## If you're in a Jupyter notebook:\n",
        "\n",
        "You have to download the image files yourself with `git clone`.\n",
        "Once you are done, the directory structure should look like\n",
        "```\n",
        "project/\n",
        "project/AI4Good---Meza-OCR-Challenge\n",
        "project/AI4Good---Meza-OCR-Challenge/cell_images, etc\n",
        "project/2019-hackathon-ocr-wymbah\n",
        "project/2019-hackathon-ocr-wymbah/nets\n",
        "project/2019-hackathon-ocr-wymbah/notebooks\n",
        "project/2019-hackathon-ocr-wymbah/util\n",
        "```\n",
        "\n",
        "You may need these commands:\n",
        "```\n",
        "git clone https://github.com/Charitable-Analytics-International/AI4Good---Meza-OCR-Challenge\n",
        "git clone https://github.com/colaprograms/2019-hackathon-ocr-wymbah\n",
        "```\n",
        "\n",
        "## If you're in Google Colab:\n",
        "\n",
        "The notebook should automatically download everything. All you have to do is hit \"Run all\" and then authorize the notebook to mount your drive so that it can save checkpoints in `My Drive/code/checkpoint`.\n",
        "\n",
        "If you run the notebook for the first time and scroll down, you should see something like\n",
        "```\n",
        "We're on Google Colab!\n",
        "Already up to date.\n",
        "Now mounting your Google Drive (not mine, yours)\n",
        "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?(et cetera)\n",
        "\n",
        "Enter your authorization code:\n",
        "```\n",
        "\n",
        "Go to the URL as instructed and enter the authorization code. The notebook will then print\n",
        "\n",
        "```\n",
        "Mounted at /content/gdrive\n",
        "Changing directory to /content/2019-hackathon-ocr-wymbah\n",
        "Checkpoints are going to /content/gdrive/My Drive/code/checkpoint\n",
        "```\n",
        "\n",
        "and then (ideally) the rest of the cells will run and it will start training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "47zAK9Hd86yi",
        "colab": {}
      },
      "source": [
        "import os, torch, re, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as p\n",
        "import random, PIL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nnmS2Npz9SDs",
        "outputId": "d7d9ad58-b971-4b8c-e969-8c4ccbc67a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "source": [
        "import os.path\n",
        "from os.path import join\n",
        "def exists(*arg):\n",
        "    return os.path.exists(join(*arg))\n",
        "def trymkdir(*arg):\n",
        "    try:\n",
        "        os.mkdir(join(*arg))\n",
        "        print(\"Created directory\", join(*arg))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "if exists(\"/content\"):\n",
        "    PATH = \"/content\"\n",
        "    print(\"We're on Google Colab!\")\n",
        "    print(\"We will automatically try to download everything.\")\n",
        "    os.chdir(PATH)\n",
        "    if not exists(PATH, \"AI4Good---Meza-OCR-Challenge\"):\n",
        "      !git clone https://github.com/Charitable-Analytics-International/AI4Good---Meza-OCR-Challenge\n",
        "    if not exists(PATH, \"2019-hackathon-ocr-wymbah\"):\n",
        "      !git clone https://github.com/colaprograms/2019-hackathon-ocr-wymbah\n",
        "    CODE_PATH = join(PATH, \"2019-hackathon-ocr-wymbah\")\n",
        "    \"The code may have changed on GitHub since we cloned it\"\n",
        "    os.chdir(CODE_PATH)\n",
        "    !git pull\n",
        "    \n",
        "    \"Mount Google Drive on /content/gdrive/My Drive and try to save checkpoints in code/checkpoint\"\n",
        "    print(\"Now mounting your Google Drive (not mine, yours)\")\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "    trymkdir(\"/content/gdrive/My Drive/code\")\n",
        "    trymkdir(\"/content/gdrive/My Drive/code/checkpoint\")\n",
        "    CHECKPOINT_PATH = \"/content/gdrive/My Drive/code/checkpoint\"\n",
        "else:\n",
        "    print(\"We're in a Jupyter notebook!\")\n",
        "    print(\"We will NOT automatically get the training files or pull from git.\")\n",
        "    if exists(\"../notebooks\"):\n",
        "        \"Move out of the notebooks directory\"\n",
        "        os.chdir(\"..\")\n",
        "    CODE_PATH = os.getcwd()\n",
        "    CHECKPOINT_PATH = join(CODE_PATH, \"checkpoint\")\n",
        "    trymkdir(CHECKPOINT_PATH)\n",
        "\n",
        "print(\"Changing directory to\", CODE_PATH)\n",
        "os.chdir(CODE_PATH)\n",
        "print(\"Checkpoints are going to\", CHECKPOINT_PATH)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're on Google Colab!\n",
            "We will automatically try to download everything.\n",
            "Cloning into 'AI4Good---Meza-OCR-Challenge'...\n",
            "remote: Enumerating objects: 7262, done.\u001b[K\n",
            "remote: Counting objects: 100% (7262/7262), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6869/6869), done.\u001b[K\n",
            "remote: Total 7262 (delta 394), reused 7261 (delta 393), pack-reused 0\n",
            "Receiving objects: 100% (7262/7262), 8.15 MiB | 21.34 MiB/s, done.\n",
            "Resolving deltas: 100% (394/394), done.\n",
            "Cloning into '2019-hackathon-ocr-wymbah'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 378 (delta 10), reused 4 (delta 2), pack-reused 353\u001b[K\n",
            "Receiving objects: 100% (378/378), 334.19 MiB | 41.42 MiB/s, done.\n",
            "Resolving deltas: 100% (175/175), done.\n",
            "Checking out files: 100% (24/24), done.\n",
            "Already up to date.\n",
            "Now mounting your Google Drive (not mine, yours)\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Changing directory to /content/2019-hackathon-ocr-wymbah\n",
            "Checkpoints are going to /content/gdrive/My Drive/code/checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL61ucPlfA4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "# Numpy will show all numbers to 4 decimal places\n",
        "np.set_printoptions(4, suppress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RBrQBRzb9Vyp",
        "colab": {}
      },
      "source": [
        "# Reload all of our modules in case they changed\n",
        "\n",
        "modules_to_reload = [\n",
        "    \"util.file\",\n",
        "    \"util.chars\",\n",
        "    \"nets.ctcnet\"\n",
        "]\n",
        "\n",
        "from importlib import import_module, reload\n",
        "for module in modules_to_reload:\n",
        "    print(\"Reloading %s\" % module)\n",
        "    reload(import_module(module))\n",
        "    print()\n",
        "\n",
        "from util.chars import chars, nchars, idx, input_to_string\n",
        "from util.file import FileHolder\n",
        "from nets.ctcnet import CTCModel\n",
        "\n",
        "fh = FileHolder()\n",
        "print(\"Loaded %d training images and %d validation images\" %\n",
        "     (fh.ntraining(), fh.nvalidation()))\n",
        "\n",
        "def show(z):\n",
        "    print()\n",
        "    b = z[0].numpy().squeeze().transpose(1, 2, 0)\n",
        "    print(\"Label:\", z[1][0])\n",
        "    print(\"Image mean:\", np.mean(b, axis=(0, 1)))\n",
        "    print(\"Image std dev:\", np.std(b, axis=(0, 1)))\n",
        "    p.imshow(b * 0.3 + 0.9)\n",
        "    p.show()\n",
        "\n",
        "print(\"Showing an example training image\")\n",
        "b = fh.get_batch_tensor(1)\n",
        "show(b)\n",
        "\n",
        "print()\n",
        "print(\"Showing an example validation image\")\n",
        "b = fh.get_batch_tensor(1, validation=True)\n",
        "show(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gj9U2jENAnfQ",
        "outputId": "ccad114c-e738-4fba-9ab1-86e02577c43a",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "class Runner:\n",
        "    def __init__(self):\n",
        "        self.model = CTCModel().cuda()\n",
        "        self.loss = nn.CTCLoss(reduction='sum').cuda()\n",
        "        self.optimizer = optim.SGD(\n",
        "            self.model.parameters(),\n",
        "            lr = 0.0001, # It gets pretty unstable with larger lrs.\n",
        "            momentum = 0.9,\n",
        "            nesterov = True, # Everyone loves Nesterov\n",
        "            weight_decay = 0.001 # A little bit of regularization\n",
        "        )\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer,\n",
        "            patience=6,\n",
        "            verbose=True\n",
        "        )\n",
        "        self.trainloss = []\n",
        "        self.validloss = []\n",
        "        \n",
        "    def predict(self, inputs):\n",
        "        # Enter evaluation mode\n",
        "        self.model.eval()\n",
        "        return self.model(inputs.clone().cuda())\n",
        "    \n",
        "    def one_batch_loss(self, inputs, outputs):\n",
        "        inputs = self.model(inputs.clone().cuda())\n",
        "        inputs = inputs.permute(1, 0, 2)\n",
        "        # sequence, batch, channels\n",
        "        # All sequences should be 32 long, because that's\n",
        "        # the size of the image after we pad to 256 pixels\n",
        "        # and then run it through the convolutions.\n",
        "        assert inputs.shape[0] == 32\n",
        "        input_lengths = torch.tensor(\n",
        "            [32 for i in range(inputs.shape[1])],\n",
        "            dtype=torch.int32\n",
        "        )\n",
        "        target, target_lengths = Runner.maketarget(outputs)\n",
        "        \n",
        "        loss = self.loss(inputs, target, input_lengths, target_lengths)\n",
        "        return loss\n",
        "    \n",
        "    @staticmethod\n",
        "    def maketarget(outputs):\n",
        "        classes = []\n",
        "        \"Concatenate all the outputs into one array\"\n",
        "        for string in outputs:\n",
        "            classes.extend([idx[c] for c in string])\n",
        "        lengths = [len(string) for string in outputs]\n",
        "        # We use int32 because Torch promises us that we\n",
        "        # can use special CuDNN code if we meet some\n",
        "        # requirements, and one of the requirements is\n",
        "        # that these tensors have type torch.int32.\n",
        "        return (\n",
        "            torch.tensor(classes, dtype=torch.int32),\n",
        "            torch.tensor(lengths, dtype=torch.int32)\n",
        "        )\n",
        "\n",
        "    def __train(self, epoch):\n",
        "        # set training mode just in case it has somehow been unset\n",
        "        self.model.train()\n",
        "        running_loss = 0.0\n",
        "        length = 0\n",
        "        #print(\"Example output:\")\n",
        "        import time\n",
        "        if epoch == 0:\n",
        "          start = time.time()\n",
        "        for i in range(100):\n",
        "          inputs, outputs = fh.get_batch_tensor(BATCH_SIZE)\n",
        "          self.optimizer.zero_grad()\n",
        "          loss = self.one_batch_loss(inputs, outputs)\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "          length += BATCH_SIZE\n",
        "          if epoch == 0 and i == 10:\n",
        "            elapsed = time.time() - start\n",
        "            print(\"Each epoch should take about %.1f minutes.\" % (elapsed*10/60))\n",
        "            loss = None\n",
        "        trainingloss = running_loss / length\n",
        "        print(\"Epoch %d. Loss: %f\" % (epoch, trainingloss))\n",
        "        self.trainloss.append(trainingloss)\n",
        "    \n",
        "    def __valid(self, epoch):\n",
        "        running_loss = 0.0\n",
        "        length = 0\n",
        "        with torch.no_grad():\n",
        "            for i in range(100):\n",
        "                inputs, outputs = fh.get_batch_tensor(BATCH_SIZE, validation=True)\n",
        "                loss = self.one_batch_loss(inputs, outputs)\n",
        "                running_loss += loss.item()\n",
        "                length += BATCH_SIZE\n",
        "        validationloss = running_loss / length\n",
        "        self.scheduler.step(validationloss)\n",
        "        print(\"Validation loss: %f\" % validationloss)\n",
        "        self.validloss.append(validationloss)\n",
        "        file = join(CHECKPOINT_PATH, \"checkpoint-%04d-%.2f\" % (epoch, validationloss))\n",
        "        torch.save({\n",
        "            'model': self.model.state_dict(),\n",
        "            'trainloss': self.trainloss,\n",
        "            'validloss': self.validloss\n",
        "        }, file)\n",
        "        print(\"Saved\", file)\n",
        "    \n",
        "    def load_from(self, file):\n",
        "        checkpoint = torch.load(file)\n",
        "        self.model.load_state_dict(checkpoint['model'])\n",
        "        self.trainloss, self.validloss = checkpoint['trainloss'], checkpoint['validloss']\n",
        "        \n",
        "    def run(self, epochs, resume_checkpoint=None):\n",
        "        if resume_checkpoint is None:\n",
        "            print(\"Training network from scratch\")\n",
        "            print(\"Once the validation loss stops improving, you should probably stop the model.\")\n",
        "            print(\"For this model, that seems to take around 50 epochs.\")\n",
        "        else:\n",
        "            self.load_from(resume_checkpoint)\n",
        "        for epoch in range(epochs):\n",
        "            self.__train(epoch)\n",
        "            self.__valid(epoch)\n",
        "\n",
        "blade = Runner()\n",
        "blade.run(100, resume_checkpoint=None)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n",
            "100%|██████████| 87306240/87306240 [00:02<00:00, 29847857.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training network from scratch\n",
            "Once the validation loss stops improving, you should probably stop the model.\n",
            "For this model, that seems to take around 50 epochs.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:23: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
            "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Each epoch should take about 1.4 minutes.\n",
            "Epoch 0. Loss: 12.049444\n",
            "Validation loss: 7.964521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2d4d481a3d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mblade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mblade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-2d4d481a3d87>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, epochs, resume_checkpoint)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mblade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2d4d481a3d87>\u001b[0m in \u001b[0;36m__valid\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;34m'trainloss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;34m'validloss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         }, file)\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoint/checkpoint-0000-7.96'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kB7gURafA46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}